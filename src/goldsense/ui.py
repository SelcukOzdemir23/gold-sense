from __future__ import annotations

import pandas as pd
import plotly.express as px
import streamlit as st
import dspy

from .models import MarketSummary, AnalysisResult

def _trend_tr(value: str) -> str:
    mapping = {
        "Strong Bullish": "GÃ¼Ã§lÃ¼ BoÄŸa",
        "Bearish": "AyÄ±",
        "Neutral": "NÃ¶tr",
    }
    return mapping.get(value, value)

def _category_tr(value: str) -> str:
    mapping = {
        "Macro": "Makro",
        "Geopolitical": "Jeopolitik",
        "Industrial": "EndÃ¼striyel",
        "Irrelevant": "AlakasÄ±z",
    }
    return mapping.get(value, value)

def render_results(price: float | None, summary: MarketSummary, results: list[AnalysisResult], confidence_threshold: float):
    # ... (Existing code kept as is, but focusing on new function below)
    # Strategic Summary
    st.subheader("Stratejik DeÄŸerlendirme")
    
    confidence_pct = int(summary.confidence_average * 100)
    
    strategic_text = (
        f"**Piyasa EÄŸilimi:** {summary.trend} "
        f"(AÄŸÄ±rlÄ±klÄ± Skor: {summary.weighted_score:.1f}/10)\n\n"
        f"**Model EminliÄŸi:** %{confidence_pct} "
        f"(Ortalama gÃ¼ven seviyesi)\n\n"
            f"**Analiz KapsamÄ±:** {summary.relevant_articles}/{summary.total_articles} haber "
        f"altÄ±n piyasasÄ±nÄ± etkiliyor. "
        f"Makro haberler (x1.5 aÄŸÄ±rlÄ±k) diÄŸer kategorilerden daha etkili sayÄ±lmÄ±ÅŸtÄ±r."
    )
    st.info(strategic_text)
    
    st.divider()
    
    col1, col2, col3, col4 = st.columns(4)
    
    if price is None:
        col1.metric("AltÄ±n FiyatÄ±", "Veri Yok")
    else:
        col1.metric("AltÄ±n FiyatÄ±", f"{price:.2f} USD")
    
    col2.metric("EÄŸilim", _trend_tr(summary.trend))
    col3.metric("Ort. Skor", f"{summary.average_score:.1f}/10")
    col4.metric("Ä°lgili Haber", f"{summary.relevant_articles}/{summary.total_articles}")

    st.divider()

    relevant_results = [r for r in results if r.is_relevant]
    if relevant_results:
        # Top 5 Section
        top_results = sorted(relevant_results, key=lambda x: x.sentiment_score, reverse=True)[:5]
        st.subheader("Top 5 En Etkili Haber")
        for idx, item in enumerate(top_results, 1):
            _render_article_card(item, rank=idx)

    st.divider()

    # Chart Section
    _render_chart(results)

    st.divider()
    st.subheader("TÃ¼m Ä°lgili Haberler")

    if relevant_results:
        sorted_results = sorted(relevant_results, key=lambda x: x.sentiment_score, reverse=True)

        categories = sorted(set(r.category for r in sorted_results))
        category_display = ["TÃ¼mÃ¼"] + [_category_tr(c) for c in categories]
        selected_category_display = st.selectbox(
            "Kategoriye gÃ¶re filtrele:",
            category_display,
        )

        if selected_category_display == "TÃ¼mÃ¼":
            filtered = sorted_results
        else:
            filtered = [r for r in sorted_results if _category_tr(r.category) == selected_category_display]
        
        # Apply confidence filter
        filtered = [r for r in filtered if r.confidence_score >= confidence_threshold]

        for item in filtered:
            _render_article_card(item)
    else:
        st.info("Ä°lgili haber bulunamadÄ±.")

def _render_article_card(item: AnalysisResult, rank: int | None = None):
    with st.container(border=True):
        if rank:
            col_rank, col_content = st.columns([0.5, 9.5])
            col_rank.markdown(f"### #{rank}")
            container = col_content
        else:
            container = st
            
        container.markdown(f"**{item.article.title}**")
        container.write(item.article.description or "-")
        
        # Badges
        col_cat, col_score, col_conf, col_date = container.columns(4)
        col_cat.caption(f"{_category_tr(item.category)}")

        # Score badge
        if item.sentiment_score >= 7:
            score_color = ":green[High]"
        elif item.sentiment_score <= 4:
            score_color = ":red[Low]"
        else:
            score_color = ":orange[Med]"
        col_score.caption(f"{score_color} Skor: **{item.sentiment_score}/10**")
        
        # Confidence badge
        conf_pct = int(item.confidence_score * 100)
        if item.confidence_score >= 0.8:
            conf_color = ":green[High]"
        elif item.confidence_score >= 0.5:
            conf_color = ":orange[Med]"
        else:
            conf_color = ":red[Low]"
        col_conf.caption(f"{conf_color} GÃ¼ven: **%{conf_pct}**")
        
        col_date.caption(f"{item.article.published_at.strftime('%d %b %H:%M')}")

        container.write(f"*{item.impact_reasoning}*")
        
        if item.reasoning:
            with container.expander("AI Muhakeme SÃ¼reci"):
                st.caption("Modelin bu sonuca nasÄ±l vardÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz:")
                st.info(item.reasoning)

def _render_chart(results: list[AnalysisResult]):
    chart_data = pd.DataFrame(
        [
            {
                "title": r.article.title,
                "score": r.sentiment_score,
                "category": _category_tr(r.category),
                "published_at": r.article.published_at,
            }
            for r in results
            if r.is_relevant
        ]
    )

    if not chart_data.empty:
        fig = px.scatter(
            chart_data,
            x="published_at",
            y="score",
            color="category",
            hover_name="title",
            title="Haber YoÄŸunluÄŸu vs Etki PuanÄ±",
            labels={"score": "Etki PuanÄ± (1-10)", "published_at": "YayÄ±n Tarihi"},
        )
        fig.add_hline(
            y=7,
            line_dash="dash",
            line_color="green",
            annotation_text="BoÄŸa EÅŸiÄŸi",
            annotation_position="right",
        )
        fig.add_hline(
            y=4,
            line_dash="dash",
            line_color="red",
            annotation_text="AyÄ± EÅŸiÄŸi",
            annotation_position="right",
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("Grafik oluÅŸturulacak veri yok.")

def render_performance_tab(lm_history: list | None, token_usage: dict | None):
    """
    Renders detailed performance metrics and DSPy prompt inspection.
    Uses persisted session state data instead of volatile dspy.settings.lm.
    """
    st.subheader("ğŸš€ Sistem PerformansÄ± & DSPy Optimizasyonu")
    
    if not lm_history:
        st.info("HenÃ¼z analiz yapÄ±lmadÄ±. LÃ¼tfen 'Analiz' sekmesinden bir iÅŸlem baÅŸlatÄ±n.")
        return

    # 1. Token Metrics
    st.markdown("### ğŸ“Š Token ve Maliyet Analizi")
    
    last_call = lm_history[-1]
    # Try to find usage in last call or use accumulated stats
    usage = last_call.get('usage', {})
    if not usage and token_usage:
         # Fallback to session accumulated data if raw call doesn't have it
         pass 

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Toplam Ã‡aÄŸrÄ±", len(lm_history))
    col2.metric("Prompt Token", usage.get('prompt_tokens', 'N/A'))
    col3.metric("Completion Token", usage.get('completion_tokens', 'N/A'))
    col4.metric("Model", last_call.get('model', 'Unknown'))

    st.divider()

    # 2. Prompt Optimization Inspector
    st.markdown("### ğŸ§  DSPy Prompt Inspector (Few-Shot Learning)")
    st.caption("Modelin 'Train' edilmesi iÃ§in kullanÄ±lan dinamik prompt yapÄ±sÄ±. Few-Shot Ã¶rneklerinin nasÄ±l enjekte edildiÄŸini buradan gÃ¶rebilirsiniz.")

    # Extract the actual prompt sent to the model
    # Usually in 'messages' for chat models
    messages = last_call.get('messages', [])
    
    if messages:
        # User message usually contains the compiled prompt with examples
        for msg in messages:
            role = msg.get('role', '').upper()
            content = msg.get('content', '')
            
            # Simple highlighting for DSPy sections
            if "---" in content:
                st.markdown(f"#### {role} MesajÄ± (Compiled Context)")
                
                parts = content.split("---")
                
                st.markdown("**1. GÃ¶rev TalimatÄ± (Signature Instructions):**")
                st.code(parts[0].strip(), language="text")
                
                if len(parts) > 2:
                    st.markdown(f"**2. Few-Shot Ã–rnekleri ({len(parts)-2} Adet Enjekte Edildi):**")
                    with st.expander("Ã–rnekleri Ä°ncele (EÄŸitim Verisi)", expanded=True):
                        examples_text = "\n---\n".join(parts[1:-1])
                        st.code(examples_text, language="text")
                
                st.markdown("**3. Mevcut GÃ¶rev (Input):**")
                st.code(parts[-1].strip(), language="text")
                
            else:
                with st.expander(f"{role} MesajÄ±", expanded=False):
                    st.code(content, language="text")
    else:
        st.warning("Prompt geÃ§miÅŸi okunamadÄ± (Non-Chat model formatÄ± olabilir).")

    st.divider()
    
    # 3. Raw Response Validation
    with st.expander("ğŸ› ï¸ Ham Model Ã‡Ä±ktÄ±sÄ± (Raw Response)"):
        st.json(last_call)
