from __future__ import annotations

import asyncio
import json
import sys
from dataclasses import replace
from datetime import datetime, timezone
from pathlib import Path

import dspy
import pandas as pd
import plotly.express as px
import streamlit as st
from dotenv import load_dotenv

ROOT = Path(__file__).resolve().parent
SRC_PATH = ROOT / "src"
if str(SRC_PATH) not in sys.path:
    sys.path.append(str(SRC_PATH))

from goldsense.analyst import GoldAnalyst
from goldsense.config import Settings
from goldsense.engine import MarketEngine
from goldsense.exceptions import ConfigError, GoldSenseError
from goldsense.fetcher import NewsFetcher
from goldsense.logger import JsonlLogger
from goldsense.models import NewsArticle
from goldsense.price import GoldPriceService
from goldsense.tonl import decode_news_articles, encode_news_articles, encode_tonl, decode_tonl


st.set_page_config(page_title="Gold-Sense AI", layout="wide")

st.title("Gold-Sense AI")
st.caption("Finansal Haber Analizi - AltÄ±n PiyasasÄ± Tahmin Sistemi")

load_dotenv()
settings = Settings.from_env()

with st.sidebar:
    st.header("Ayarlar")
    confidence_threshold = st.slider(
        "Minimum GÃ¼ven Seviyesi",
        min_value=0.0,
        max_value=1.0,
        value=0.0,
        step=0.1,
        help="Sadece bu seviye ve Ã¼zerindeki gÃ¼ven skorlu haberleri gÃ¶ster"
    )
    st.caption(f"GÃ¶sterilecek: %{int(confidence_threshold * 100)}+ gÃ¼ven")

try:
    settings.validate()
except ConfigError as exc:
    st.error(f"Config error: {exc}")
    st.stop()

effective_settings = replace(settings)

# --- GLOBAL DSPY CONFIGURATION (Dependency Injection Root) ---
try:
    lm = dspy.LM(
        f"openai/{effective_settings.cerebras_model}",
        api_key=effective_settings.cerebras_api_key,
        api_base=effective_settings.cerebras_api_base,
        temperature=effective_settings.analysis_temperature,
        cache=False,  # Disable cache for fresh results
    )
    dspy.configure(lm=lm, track_usage=True)
except Exception as exc:
    st.error(f"Global LM Configuration Failed: {exc}")
    st.stop()

from goldsense import ui

fetcher = NewsFetcher(effective_settings)
analyst = GoldAnalyst(effective_settings)
engine = MarketEngine()

price_service = GoldPriceService(effective_settings)
logger = JsonlLogger(path=Path("logs/analysis.jsonl"))

if "raw_payload" not in st.session_state:
    st.session_state.raw_payload = None
if "tonl_text" not in st.session_state:
    st.session_state.tonl_text = None
if "analysis" not in st.session_state:
    st.session_state.analysis = None
if "lm_history" not in st.session_state:
    st.session_state.lm_history = None
if "token_usage" not in st.session_state:
    st.session_state.token_usage = None


def _run_fetch_sync(fetcher: NewsFetcher) -> tuple[list[NewsArticle], dict]:
    """Sync wrapper for async news fetching"""
    return asyncio.run(fetcher.fetch_latest_with_payload())


def _run_analysis_sync(analyst: GoldAnalyst, articles: list[NewsArticle]):
    return asyncio.run(analyst.analyze_articles(articles))


def _to_article(item: dict) -> NewsArticle:
    published_raw = item.get("published_at") or item.get("publishedAt")
    if isinstance(published_raw, str) and published_raw:
        try:
            published_at = datetime.fromisoformat(published_raw.replace("Z", "+00:00"))
        except ValueError:
            published_at = datetime.now(timezone.utc)
    else:
        published_at = datetime.now(timezone.utc)

    return NewsArticle(
        title=(item.get("title") or "").strip(),
        description=(item.get("description") or "").strip(),
        published_at=published_at,
        source=item.get("source"),
        url=item.get("url"),
    )


tab_fetch, tab_tonl, tab_analyze, tab_curiosity = st.tabs(
    ["Haber HasadÄ±", "TONL", "Analiz", "Performans"]
)

with tab_fetch:
    st.subheader("ğŸ“° Haber HasadÄ±")
    st.caption("NewsAPI'den altÄ±n ile ilgili son haberleri Ã§eker")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        if st.button("ğŸ“¥ Haberleri Getir", type="primary", key="fetch_news", use_container_width=True):
            with st.spinner("ğŸ”„ Haberler Ã§ekiliyor..."):
                try:
                    articles, payload = _run_fetch_sync(fetcher)
                except GoldSenseError as exc:
                    st.error(f"âŒ Haber Ã§ekme hatasÄ±: {exc}")
                    st.stop()

            st.session_state.raw_payload = payload
            Path("logs").mkdir(parents=True, exist_ok=True)
            (Path("logs") / "raw_news.json").write_text(
                json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8"
            )
            
            # Success metrics
            col_a, col_b, col_c = st.columns(3)
            col_a.metric("ğŸ“Š Ã‡ekilen Haber", len(articles))
            col_b.metric("ğŸ“… Tarih AralÄ±ÄŸÄ±", f"{settings.lookback_days} gÃ¼n")
            col_c.metric("ğŸ’¾ Dosya", "raw_news.json")
            
            st.success(f"âœ… {len(articles)} haber baÅŸarÄ±yla Ã§ekildi!")
    
    with col2:
        if st.session_state.raw_payload:
            total_articles = len(st.session_state.raw_payload.get("articles", []))
            st.metric("ğŸ“ˆ Toplam", total_articles)
            st.caption("Ã‡ekilen haber sayÄ±sÄ±")

    if st.session_state.raw_payload:
        st.divider()
        
        # Quick preview of articles
        articles = st.session_state.raw_payload.get("articles", [])
        if articles:
            st.subheader("ğŸ” Haber Ã–nizleme")
            
            # Show first 3 articles as preview
            for i, article in enumerate(articles[:3]):
                with st.container(border=True):
                    st.markdown(f"**{article.get('title', 'BaÅŸlÄ±k yok')}**")
                    st.caption(f"ğŸ“° {article.get('source', {}).get('name', 'Bilinmeyen kaynak')} | "
                             f"ğŸ“… {article.get('publishedAt', 'Tarih yok')[:10]}")
                    if article.get('description'):
                        st.write(article['description'][:150] + "..." if len(article.get('description', '')) > 150 else article['description'])
            
            if len(articles) > 3:
                st.caption(f"... ve {len(articles) - 3} haber daha")
        
        st.divider()
        st.caption("ğŸ”§ Ham JSON verisi (NewsAPI payload)")
        with st.expander("ğŸ“‹ Ham JSON'u GÃ¶r", expanded=False):
            st.json(st.session_state.raw_payload)
    else:
        st.info("ğŸ‘† Haberleri Ã§ekmek iÃ§in yukarÄ±daki butona tÄ±klayÄ±n.")

with tab_tonl:
    subtab_news, subtab_playground = st.tabs(["ğŸ“° Haber DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼", "ğŸ® Playground"])
    
    with subtab_news:
        if not st.session_state.raw_payload:
            st.info("Ã–nce 1. adÄ±mÄ± tamamla (haberleri Ã§ek).")
        else:
            if st.button("TONL'e Ã‡evir (Haberler)", type="primary", key="convert_tonl_news"):
                raw_articles = st.session_state.raw_payload.get("articles", [])
                tonl_text = encode_news_articles(raw_articles)
                st.session_state.tonl_text = tonl_text

                Path("logs").mkdir(parents=True, exist_ok=True)
                (Path("logs") / "news.tonl").write_text(tonl_text, encoding="utf-8")

            if st.session_state.tonl_text:
                raw_articles = st.session_state.raw_payload.get("articles", [])
                json_text = json.dumps(raw_articles, ensure_ascii=False)
                tonl_text = st.session_state.tonl_text

                json_chars = len(json_text)
                tonl_chars = len(tonl_text)
                savings = (1 - (tonl_chars / json_chars)) * 100 if json_chars else 0

                col1, col2, col3 = st.columns(3)
                col1.metric("JSON Karakter", f"{json_chars}")
                col2.metric("TONL Karakter", f"{tonl_chars}")
                col3.metric("Tasarruf", f"%{savings:.1f}")

                col_json, col_tonl = st.columns(2)
                with col_json:
                    st.caption("JSON (Ham)")
                    with st.expander("TÄ±kla: JSON FormatÄ±nÄ± GÃ¶ster", expanded=False):
                        st.code(json.dumps(raw_articles, ensure_ascii=False, indent=2), language="json")
                with col_tonl:
                    st.caption("TONL (Optimize)")
                    with st.expander("TÄ±kla: TONL FormatÄ±nÄ± GÃ¶ster", expanded=False):
                        st.code(tonl_text, language="text")
            else:
                st.info("TONL dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in butona bas.")

    with subtab_playground:
        st.subheader("ğŸ› ï¸ TONL Playground")
        st.caption("Genel amaÃ§lÄ± JSON <-> TONL dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼. Haberlerden baÄŸÄ±msÄ±z test edebilirsiniz.")
        
        col_p1, col_p2 = st.columns(2)
        
        with col_p1:
            st.markdown("### JSON -> TONL")
            pg_json_input = st.text_area("JSON Verisi Giriniz:", height=300, placeholder='{"key": "value", "list": [1, 2]}')
            
            if st.button("Encode to TONL", key="pg_encode"):
                if not pg_json_input.strip():
                    st.warning("LÃ¼tfen JSON verisi girin.")
                else:
                    try:
                        data = json.loads(pg_json_input)
                        encoded = encode_tonl(data)
                        
                        chars_j = len(pg_json_input)
                        chars_t = len(encoded)
                        sav = (1 - (chars_t / chars_j)) * 100 if chars_j else 0
                        
                        st.success(f"DÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼! Tasarruf: %{sav:.1f}")
                        st.code(encoded, language="text")
                    except json.JSONDecodeError as e:
                        st.error(f"GeÃ§ersiz JSON: {e}")
                    except Exception as e:
                        st.error(f"Hata: {e}")

        with col_p2:
            st.markdown("### TONL -> JSON")
            pg_tonl_input = st.text_area("TONL Verisi Giriniz:", height=300, placeholder='#version 1.0\nroot:\n  key: "value"')
            
            if st.button("Decode to JSON", key="pg_decode"):
                if not pg_tonl_input.strip():
                    st.warning("LÃ¼tfen TONL verisi girin.")
                else:
                    try:
                        decoded = decode_tonl(pg_tonl_input)
                        st.success("DÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼!")
                        st.json(decoded)
                    except Exception as e:
                        st.error(f"Hata: {e}")

with tab_analyze:
    if not st.session_state.tonl_text:
        st.info("Ã–nce 2. adÄ±mÄ± tamamla (TONL'e Ã§evir).")
    else:
        if st.button("Analizi BaÅŸlat", type="primary", key="run_analysis"):
            # STEP 1: Fetch gold price first (non-blocking)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("AltÄ±n fiyatÄ± sorgulanÄ±yor...")
            progress_bar.progress(10)
            
            price = price_service.get_current_price()
            
            if price is None:
                st.warning("AltÄ±n fiyat bilgisi alÄ±namadÄ± (Truncgil/Binance yanÄ±t vermedi). Analiz devam ediyor...")
            else:
                st.success(f"âœ… GÃ¼ncel altÄ±n fiyatÄ±: **${price:.2f}**")
            
            progress_bar.progress(20)
            
            # STEP 2: Parse TONL
            status_text.text("ğŸ“„ TONL verisi decode ediliyor...")
            tonl_items = decode_news_articles(st.session_state.tonl_text)
            articles = [_to_article(item) for item in tonl_items]
            progress_bar.progress(30)
            
            # STEP 3: Run analysis with progress updates
            status_text.text(f"{len(articles)} haber DSPy ile analiz ediliyor...")
            try:
                
                # Analyze articles (this is the heavy operation)

                results = _run_analysis_sync(analyst, articles)
                progress_bar.progress(80)
                
                # Log results
                status_text.text("ğŸ’¾ SonuÃ§lar kaydediliyor...")
                for result in results:
                    logger.log(result)
                progress_bar.progress(90)

                # Generate summary
                status_text.text("Ã–zet rapor oluÅŸturuluyor...")
                summary = engine.summarize(results)
                
                # Capture LM history and usage for debug console
                lm = dspy.settings.lm
                st.session_state.lm_history = lm.history[-min(3, len(lm.history)):] if lm.history else []
                
                # Get token usage from last result if available
                if results:
                    # Store token usage info
                    st.session_state.token_usage = {
                        'total_calls': len(results),
                        'history_count': len(lm.history) if lm.history else 0
                    }
                
                progress_bar.progress(100)
                status_text.text("âœ… TamamlandÄ±!")
                
            except GoldSenseError as exc:
                st.error(f"Ã‡alÄ±ÅŸtÄ±rma hatasÄ±: {exc}")
                st.stop()

            st.session_state.analysis = (price, summary, results)
            st.success("âœ… Analiz tamamlandÄ±! AÅŸaÄŸÄ±da sonuÃ§larÄ± gÃ¶rebilirsin.")
            st.rerun()  # Refresh to show results

        if st.session_state.analysis:
            price, summary, results = st.session_state.analysis
            ui.render_results(price, summary, results, confidence_threshold)
            
            # Token Usage Summary
            if st.session_state.token_usage:
                st.divider()
                st.subheader("Token KullanÄ±m Ä°statistikleri")
                col1, col2 = st.columns(2)
                col1.metric("Toplam LM Ã‡aÄŸrÄ±sÄ±", st.session_state.token_usage.get('total_calls', 0))
                col2.metric("History KayÄ±t SayÄ±sÄ±", st.session_state.token_usage.get('history_count', 0))
                
                # Show usage details if available
                lm = dspy.settings.lm
                if hasattr(lm, 'history') and lm.history:
                    st.caption("Son LM Ã§aÄŸrÄ±sÄ± detaylarÄ±:")
                    last_call = lm.history[-1]
                    if 'usage' in last_call and last_call['usage']:
                        usage_data = last_call['usage']
                        col_a, col_b, col_c = st.columns(3)
                        col_a.metric("Prompt Tokens", usage_data.get('prompt_tokens', 'N/A'))
                        col_b.metric("Completion Tokens", usage_data.get('completion_tokens', 'N/A'))
                        col_c.metric("Total Tokens", usage_data.get('total_tokens', 'N/A'))
        else:
            # Informative onboarding panel
            st.markdown("### ğŸ¯ HoÅŸgeldiniz - Sistem Rehberi")
            
            with st.container(border=True):
                st.markdown("""
                **AmaÃ§:**  
                Bu sistem, kÃ¼resel finans haberlerinin **altÄ±n piyasalarÄ±** Ã¼zerindeki olasÄ± etkilerini yapay zeka ile analiz eder.
                Haberleri okuyup puanlayarak, piyasanÄ±n hangi yÃ¶nde hareket edebileceÄŸini tahmin eder.
                
                ---
                
                **ğŸ“Š EÄŸilim Terimleri:**
                
                - ğŸŸ¢ **GÃ¼Ã§lÃ¼ BoÄŸa (Strong Bullish):** AltÄ±n fiyatlarÄ±nda **gÃ¼Ã§lÃ¼ yÃ¼kseliÅŸ** beklentisi.  
                  *Ã–rnek: "Fed faiz indirdi" haberi â†’ AltÄ±n talebi artar â†’ Fiyat yÃ¼kselir.*
                
                - ğŸ”´ **AyÄ± (Bearish):** AltÄ±n fiyatlarÄ±nda **dÃ¼ÅŸÃ¼ÅŸ** beklentisi.  
                  *Ã–rnek: "GÃ¼Ã§lÃ¼ istihdam verisi" â†’ Fed faizleri yÃ¼ksek tutar â†’ AltÄ±n Ã§ekiciliÄŸi azalÄ±r.*
                
                - âšª **NÃ¶tr (Neutral):** Piyasada **yatay seyir** veya belirgin bir etki yok.  
                  *Ã–rnek: AltÄ±nla doÄŸrudan ilgisi olmayan teknoloji haberleri.*
                
                ---
                
                **âš™ï¸ Sistem NasÄ±l Ã‡alÄ±ÅŸÄ±r?**
                
                1. **Haber Analizi:** AI (Llama-3 70B) her haberi okur ve 1-10 arasÄ± puan verir.
                2. **AÄŸÄ±rlÄ±klÄ± DeÄŸerlendirme:** Makro haberler (Fed kararlarÄ±, enflasyon) daha yÃ¼ksek aÄŸÄ±rlÄ±k alÄ±r.
                3. **Trend Tahmini:** TÃ¼m skorlar birleÅŸtirilerek genel piyasa eÄŸilimi belirlenir.
                4. **AÃ§Ä±klama:** Model sadece sonuÃ§ vermez, *neden* bu karara vardÄ±ÄŸÄ±nÄ± da aÃ§Ä±klar (Chain-of-Thought).
                
                ---
                
                âš ï¸ **Not:** Bu analiz sadece bilgilendirme amaÃ§lÄ±dÄ±r. YatÄ±rÄ±m tavsiyesi deÄŸildir.
                """)
            
            st.info("ğŸ‘† HazÄ±r olduÄŸunda yukarÄ±daki butona basarak analizi baÅŸlatabilirsin.")

with tab_curiosity:
    # Use global session state token usage if available
    usage_data = st.session_state.token_usage if "token_usage" in st.session_state else None
    lm_history_data = st.session_state.lm_history if "lm_history" in st.session_state else None
    ui.render_performance_tab(lm_history_data, usage_data)

